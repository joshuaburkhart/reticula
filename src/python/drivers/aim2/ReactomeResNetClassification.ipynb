{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ReactomeResNetClassification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNi1uLjiIHdI6VToDpSGs3q"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDals46Va8lO","executionInfo":{"status":"ok","timestamp":1621546645907,"user_tz":420,"elapsed":251,"user":{"displayName":"Joshua Burkhart","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjidOj0S08p-oMefD8YPB2WkZJ3VJ7uGJVOciG9=s64","userId":"10944155218452146273"}},"outputId":"090a451e-6d57-41de-92b3-b39dc4524dc5"},"source":["import torch\n","from torch import nn\n","import torchvision.models as models\n","\n","# data can be reshaped to rectangular matrices:\n","#     62 × 173 = 10,726\n","#     31 × 346 = 10,726\n","#     2 x 31 x 173 = 10,726\n","\n","# change shape like this?\n","#     x = x.view(x.size(0), 1, x.size(2)*16, x.size(3)*16) # [batch_size, 1, 32, 32]\n","# or like this?\n","#     a.resize_((1,5))\n","# or like this?\n","#     y = x.reshape(1, 2, 1, 3)\n","\n","# rebuild first conv layer like this?\n","#     model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False) # For torchvision.models.resnet18\n","# or like this?\n","#     model = models.resnet50()\n","#     conv1 = model.conv1\n","#     model.conv1 = nn.Conv2d(\n","#         1024, conv1.out_channels, conv1.kernel_size, conv1.stride, conv1.padding,\n","#         conv.dilation, conv1.groups, conv1.bias)\n","\n","model = models.resnet18(num_classes=51)\n","conv1 = model.conv1\n","model.conv1 = nn.Conv2d(\n","  2, conv1.out_channels, conv1.kernel_size, conv1.stride, conv1.padding,\n","  conv1.dilation, conv1.groups, conv1.bias)\n","print(model)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=51, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3hwFWckt8uHh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621546647009,"user_tz":420,"elapsed":310,"user":{"displayName":"Joshua Burkhart","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjidOj0S08p-oMefD8YPB2WkZJ3VJ7uGJVOciG9=s64","userId":"10944155218452146273"}},"outputId":"ff66aa24-5a2d-4af0-cf1c-523d2fea18e3"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!ls '/content/gdrive/My Drive/Academia/OHSU/Proposal/Aim 2/Target Sets/resnet_graph_targets.txt'\n","!ls '/content/gdrive/My Drive/Academia/OHSU/Proposal/Aim 2/Node Features/node_features.txt'"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","'/content/gdrive/My Drive/Academia/OHSU/Proposal/Aim 2/Target Sets/resnet_graph_targets.txt'\n","'/content/gdrive/My Drive/Academia/OHSU/Proposal/Aim 2/Node Features/node_features.txt'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jxBlaG4UwzDQ","executionInfo":{"status":"ok","timestamp":1621546647011,"user_tz":420,"elapsed":15,"user":{"displayName":"Joshua Burkhart","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjidOj0S08p-oMefD8YPB2WkZJ3VJ7uGJVOciG9=s64","userId":"10944155218452146273"}}},"source":["import random\n","device = cuda0 = torch.device('cuda:0')\n","cpu = torch.device('cpu')\n","\n","# from https://discuss.pytorch.org/t/how-to-define-train-mask-val-mask-test-mask-in-my-own-dataset/56289\n","features_fn = '/content/gdrive/My Drive/Academia/OHSU/Proposal/Aim 2/Node Features/node_features.txt'\n","graph_targets_fn = '/content/gdrive/My Drive/Academia/OHSU/Proposal/Aim 2/Target Sets/resnet_graph_targets.txt'\n","\n","# magic numbers\n","INPUT_CHANNELS = 1\n","OUTPUT_CHANNELS = 51\n","BATCH_SIZE = 64\n","EPOCHS = 500 #set this to 200 - 2000\n","BENCHMARKING = False\n","random.seed = 88888888"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"jqa1gup-wuCJ","executionInfo":{"status":"ok","timestamp":1621546647012,"user_tz":420,"elapsed":13,"user":{"displayName":"Joshua Burkhart","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjidOj0S08p-oMefD8YPB2WkZJ3VJ7uGJVOciG9=s64","userId":"10944155218452146273"}}},"source":["# we'll need the target encoder from this code block... not sure if we need anything else\n","def build_resnet_datalist(node_features_fn, graph_targets_fn):\n","    feature_v = numpy.loadtxt(node_features_fn)\n","    target_v = numpy.loadtxt(graph_targets_fn,dtype=str,delimiter=\"\\n\")\n","    \n","    target_encoder = sklearn.preprocessing.LabelEncoder()\n","    target_v = target_encoder.fit_transform(target_v)\n","\n","    data_list = []\n","    for row_idx in range(len(feature_v)):\n","      x = torch.tensor(feature_v[row_idx,:],dtype=torch.float)\n","      x = x.reshape(2,31,173)\n","      y = torch.tensor([target_v[row_idx]])\n","      data_list.append({'x':x,'y':y})\n","\n","    return data_list\n","\n","def build_reactome_graph_loader(data_list,batch_size):\n","\n","    loader = DataLoader(data_list,batch_size=batch_size,shuffle=True)\n","\n","    return loader"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6BFpkoB3oie","executionInfo":{"status":"ok","timestamp":1621546709815,"user_tz":420,"elapsed":62813,"user":{"displayName":"Joshua Burkhart","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjidOj0S08p-oMefD8YPB2WkZJ3VJ7uGJVOciG9=s64","userId":"10944155218452146273"}}},"source":["import numpy\n","import sklearn\n","from sklearn import preprocessing\n","from torch.utils.data import Dataset, DataLoader\n","data_list = build_resnet_datalist(features_fn, graph_targets_fn)\n","random.shuffle(data_list)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwNMe3aCJW-d","executionInfo":{"status":"ok","timestamp":1621546715767,"user_tz":420,"elapsed":5958,"user":{"displayName":"Joshua Burkhart","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjidOj0S08p-oMefD8YPB2WkZJ3VJ7uGJVOciG9=s64","userId":"10944155218452146273"}}},"source":["model = model.to(device)\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def train(loader,device):\n","  model.train()\n","\n","  for batch in loader:  # Iterate in batches over the training dataset.\n","    x = batch['x'].to(device)\n","    y = batch['y'].to(device)\n","    out = model(x)  # Perform a single forward pass.\n","    y = torch.squeeze(y)\n","    loss = criterion(out, y)  # Compute the loss.\n","    loss.backward()  # Derive gradients.\n","    optimizer.step()  # Update parameters based on gradients.\n","    optimizer.zero_grad()  # Clear gradients.\n","\n","def test(loader,device):\n","  model.eval()\n","\n","  correct = 0\n","  for batch in loader:  # Iterate in batches over the training/test dataset.\n","    x = batch['x'].to(device)\n","    y = batch['y'].to(device)\n","    out = model(x)  # Perform a single forward pass.\n","    y = torch.squeeze(y)\n","    loss = criterion(out, y)  # Compute the loss.\n","    pred = out.argmax(dim=1)  # Use the class with highest probability.\n","    correct += int((pred == y).sum())  # Check against ground-truth labels.\n","  return correct / len(loader.dataset)  # Derive ratio of correct predictions."],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05RsrQx44suy","executionInfo":{"status":"ok","timestamp":1621548207436,"user_tz":420,"elapsed":1491679,"user":{"displayName":"Joshua Burkhart","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjidOj0S08p-oMefD8YPB2WkZJ3VJ7uGJVOciG9=s64","userId":"10944155218452146273"}},"outputId":"79918760-df35-4fb0-db02-cb3652861126"},"source":["acc_str = ''\n","fold = 'full_dataset'\n","fold_size = 911\n","\n","#>>> train =              z[:fold_size * (fold - 1)] +         z[fold_size * fold:]\n","#train_data_list = data_list[:fold_size * (fold - 1)] + data_list[fold_size * fold:]\n","#>>> test =              z[fold_size * (fold - 1):fold_size * fold]\n","#test_data_list = data_list[fold_size * (fold - 1):fold_size * fold]\n","train_data_list = data_list\n","\n","print(f'Number of training examples: {len(train_data_list)}')\n","#print(f'Number of test examples: {len(test_data_list)}')\n","train_data_loader = build_reactome_graph_loader(train_data_list,BATCH_SIZE)\n","#test_data_loader = build_reactome_graph_loader(test_data_list,BATCH_SIZE)\n","for epoch in range(EPOCHS):\n","  train(train_data_loader,device)\n","  train_acc = test(train_data_loader,device)\n","  #test_acc = test(test_data_loader,device)\n","  acc_str += f'{train_acc:.4f}'#',{test_acc:.4f}\\n'\n","  print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')#', Test Acc: {test_acc:.4f}')\n","\n","training_acc_fn = F\"resnet_classification_acc_fold_{fold}.txt\"\n","path = F\"/content/gdrive/My Drive/Academia/OHSU/Proposal/resnet_{training_acc_fn}\"\n","with open(path, 'w') as writefile:\n","    writefile.write(acc_str)\n","model_save_name = F\"trained_pytorch_model_fold_{fold}.pt\"\n","path = F\"/content/gdrive/My Drive/Academia/OHSU/Proposal/resnet_{model_save_name}\" \n","torch.save(model.state_dict(), path)\n","print(F\"model saved as {path}\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Number of training examples: 9115\n","Epoch: 000, Train Acc: 0.8018\n","Epoch: 001, Train Acc: 0.8919\n","Epoch: 002, Train Acc: 0.9358\n","Epoch: 003, Train Acc: 0.9401\n","Epoch: 004, Train Acc: 0.9533\n","Epoch: 005, Train Acc: 0.9536\n","Epoch: 006, Train Acc: 0.9521\n","Epoch: 007, Train Acc: 0.9560\n","Epoch: 008, Train Acc: 0.9738\n","Epoch: 009, Train Acc: 0.9706\n","Epoch: 010, Train Acc: 0.9650\n","Epoch: 011, Train Acc: 0.9646\n","Epoch: 012, Train Acc: 0.9681\n","Epoch: 013, Train Acc: 0.9930\n","Epoch: 014, Train Acc: 0.9876\n","Epoch: 015, Train Acc: 0.9941\n","Epoch: 016, Train Acc: 0.9850\n","Epoch: 017, Train Acc: 0.9865\n","Epoch: 018, Train Acc: 0.9867\n","Epoch: 019, Train Acc: 0.9897\n","Epoch: 020, Train Acc: 0.9841\n","Epoch: 021, Train Acc: 0.9810\n","Epoch: 022, Train Acc: 0.9929\n","Epoch: 023, Train Acc: 0.9937\n","Epoch: 024, Train Acc: 0.9799\n","Epoch: 025, Train Acc: 0.9948\n","Epoch: 026, Train Acc: 0.9955\n","Epoch: 027, Train Acc: 0.9979\n","Epoch: 028, Train Acc: 0.9925\n","Epoch: 029, Train Acc: 0.9940\n","Epoch: 030, Train Acc: 0.9498\n","Epoch: 031, Train Acc: 0.9696\n","Epoch: 032, Train Acc: 0.9912\n","Epoch: 033, Train Acc: 0.9911\n","Epoch: 034, Train Acc: 0.9970\n","Epoch: 035, Train Acc: 0.9974\n","Epoch: 036, Train Acc: 0.9943\n","Epoch: 037, Train Acc: 0.9966\n","Epoch: 038, Train Acc: 0.9984\n","Epoch: 039, Train Acc: 0.9973\n","Epoch: 040, Train Acc: 0.9979\n","Epoch: 041, Train Acc: 0.9990\n","Epoch: 042, Train Acc: 0.9959\n","Epoch: 043, Train Acc: 0.9982\n","Epoch: 044, Train Acc: 0.9930\n","Epoch: 045, Train Acc: 0.9959\n","Epoch: 046, Train Acc: 0.9964\n","Epoch: 047, Train Acc: 0.9866\n","Epoch: 048, Train Acc: 0.9691\n","Epoch: 049, Train Acc: 0.9863\n","Epoch: 050, Train Acc: 0.9940\n","Epoch: 051, Train Acc: 0.9978\n","Epoch: 052, Train Acc: 0.9962\n","Epoch: 053, Train Acc: 0.9980\n","Epoch: 054, Train Acc: 0.9984\n","Epoch: 055, Train Acc: 0.9990\n","Epoch: 056, Train Acc: 0.9996\n","Epoch: 057, Train Acc: 0.9997\n","Epoch: 058, Train Acc: 0.9998\n","Epoch: 059, Train Acc: 1.0000\n","Epoch: 060, Train Acc: 1.0000\n","Epoch: 061, Train Acc: 1.0000\n","Epoch: 062, Train Acc: 1.0000\n","Epoch: 063, Train Acc: 1.0000\n","Epoch: 064, Train Acc: 1.0000\n","Epoch: 065, Train Acc: 1.0000\n","Epoch: 066, Train Acc: 1.0000\n","Epoch: 067, Train Acc: 1.0000\n","Epoch: 068, Train Acc: 1.0000\n","Epoch: 069, Train Acc: 1.0000\n","Epoch: 070, Train Acc: 1.0000\n","Epoch: 071, Train Acc: 1.0000\n","Epoch: 072, Train Acc: 1.0000\n","Epoch: 073, Train Acc: 1.0000\n","Epoch: 074, Train Acc: 1.0000\n","Epoch: 075, Train Acc: 1.0000\n","Epoch: 076, Train Acc: 1.0000\n","Epoch: 077, Train Acc: 1.0000\n","Epoch: 078, Train Acc: 1.0000\n","Epoch: 079, Train Acc: 1.0000\n","Epoch: 080, Train Acc: 1.0000\n","Epoch: 081, Train Acc: 1.0000\n","Epoch: 082, Train Acc: 1.0000\n","Epoch: 083, Train Acc: 1.0000\n","Epoch: 084, Train Acc: 1.0000\n","Epoch: 085, Train Acc: 1.0000\n","Epoch: 086, Train Acc: 1.0000\n","Epoch: 087, Train Acc: 1.0000\n","Epoch: 088, Train Acc: 1.0000\n","Epoch: 089, Train Acc: 1.0000\n","Epoch: 090, Train Acc: 1.0000\n","Epoch: 091, Train Acc: 1.0000\n","Epoch: 092, Train Acc: 1.0000\n","Epoch: 093, Train Acc: 1.0000\n","Epoch: 094, Train Acc: 1.0000\n","Epoch: 095, Train Acc: 1.0000\n","Epoch: 096, Train Acc: 1.0000\n","Epoch: 097, Train Acc: 1.0000\n","Epoch: 098, Train Acc: 1.0000\n","Epoch: 099, Train Acc: 1.0000\n","Epoch: 100, Train Acc: 1.0000\n","Epoch: 101, Train Acc: 1.0000\n","Epoch: 102, Train Acc: 1.0000\n","Epoch: 103, Train Acc: 1.0000\n","Epoch: 104, Train Acc: 1.0000\n","Epoch: 105, Train Acc: 1.0000\n","Epoch: 106, Train Acc: 1.0000\n","Epoch: 107, Train Acc: 1.0000\n","Epoch: 108, Train Acc: 1.0000\n","Epoch: 109, Train Acc: 1.0000\n","Epoch: 110, Train Acc: 1.0000\n","Epoch: 111, Train Acc: 1.0000\n","Epoch: 112, Train Acc: 1.0000\n","Epoch: 113, Train Acc: 1.0000\n","Epoch: 114, Train Acc: 1.0000\n","Epoch: 115, Train Acc: 1.0000\n","Epoch: 116, Train Acc: 1.0000\n","Epoch: 117, Train Acc: 1.0000\n","Epoch: 118, Train Acc: 1.0000\n","Epoch: 119, Train Acc: 1.0000\n","Epoch: 120, Train Acc: 1.0000\n","Epoch: 121, Train Acc: 1.0000\n","Epoch: 122, Train Acc: 1.0000\n","Epoch: 123, Train Acc: 1.0000\n","Epoch: 124, Train Acc: 1.0000\n","Epoch: 125, Train Acc: 1.0000\n","Epoch: 126, Train Acc: 1.0000\n","Epoch: 127, Train Acc: 1.0000\n","Epoch: 128, Train Acc: 1.0000\n","Epoch: 129, Train Acc: 1.0000\n","Epoch: 130, Train Acc: 1.0000\n","Epoch: 131, Train Acc: 1.0000\n","Epoch: 132, Train Acc: 1.0000\n","Epoch: 133, Train Acc: 1.0000\n","Epoch: 134, Train Acc: 1.0000\n","Epoch: 135, Train Acc: 1.0000\n","Epoch: 136, Train Acc: 1.0000\n","Epoch: 137, Train Acc: 1.0000\n","Epoch: 138, Train Acc: 1.0000\n","Epoch: 139, Train Acc: 1.0000\n","Epoch: 140, Train Acc: 1.0000\n","Epoch: 141, Train Acc: 1.0000\n","Epoch: 142, Train Acc: 1.0000\n","Epoch: 143, Train Acc: 1.0000\n","Epoch: 144, Train Acc: 1.0000\n","Epoch: 145, Train Acc: 1.0000\n","Epoch: 146, Train Acc: 0.8940\n","Epoch: 147, Train Acc: 0.9651\n","Epoch: 148, Train Acc: 0.9937\n","Epoch: 149, Train Acc: 0.9944\n","Epoch: 150, Train Acc: 0.9959\n","Epoch: 151, Train Acc: 0.9971\n","Epoch: 152, Train Acc: 0.9978\n","Epoch: 153, Train Acc: 0.9985\n","Epoch: 154, Train Acc: 0.9999\n","Epoch: 155, Train Acc: 0.9996\n","Epoch: 156, Train Acc: 0.9967\n","Epoch: 157, Train Acc: 0.9958\n","Epoch: 158, Train Acc: 0.9995\n","Epoch: 159, Train Acc: 0.9993\n","Epoch: 160, Train Acc: 0.9765\n","Epoch: 161, Train Acc: 0.9923\n","Epoch: 162, Train Acc: 0.9979\n","Epoch: 163, Train Acc: 0.9967\n","Epoch: 164, Train Acc: 0.9959\n","Epoch: 165, Train Acc: 0.9975\n","Epoch: 166, Train Acc: 0.9971\n","Epoch: 167, Train Acc: 0.9964\n","Epoch: 168, Train Acc: 0.9990\n","Epoch: 169, Train Acc: 0.9991\n","Epoch: 170, Train Acc: 0.9997\n","Epoch: 171, Train Acc: 0.9999\n","Epoch: 172, Train Acc: 0.9999\n","Epoch: 173, Train Acc: 1.0000\n","Epoch: 174, Train Acc: 1.0000\n","Epoch: 175, Train Acc: 0.9999\n","Epoch: 176, Train Acc: 1.0000\n","Epoch: 177, Train Acc: 1.0000\n","Epoch: 178, Train Acc: 1.0000\n","Epoch: 179, Train Acc: 1.0000\n","Epoch: 180, Train Acc: 1.0000\n","Epoch: 181, Train Acc: 1.0000\n","Epoch: 182, Train Acc: 1.0000\n","Epoch: 183, Train Acc: 1.0000\n","Epoch: 184, Train Acc: 1.0000\n","Epoch: 185, Train Acc: 1.0000\n","Epoch: 186, Train Acc: 1.0000\n","Epoch: 187, Train Acc: 1.0000\n","Epoch: 188, Train Acc: 1.0000\n","Epoch: 189, Train Acc: 1.0000\n","Epoch: 190, Train Acc: 1.0000\n","Epoch: 191, Train Acc: 1.0000\n","Epoch: 192, Train Acc: 1.0000\n","Epoch: 193, Train Acc: 1.0000\n","Epoch: 194, Train Acc: 1.0000\n","Epoch: 195, Train Acc: 1.0000\n","Epoch: 196, Train Acc: 1.0000\n","Epoch: 197, Train Acc: 1.0000\n","Epoch: 198, Train Acc: 1.0000\n","Epoch: 199, Train Acc: 1.0000\n","Epoch: 200, Train Acc: 1.0000\n","Epoch: 201, Train Acc: 1.0000\n","Epoch: 202, Train Acc: 1.0000\n","Epoch: 203, Train Acc: 1.0000\n","Epoch: 204, Train Acc: 1.0000\n","Epoch: 205, Train Acc: 1.0000\n","Epoch: 206, Train Acc: 1.0000\n","Epoch: 207, Train Acc: 1.0000\n","Epoch: 208, Train Acc: 1.0000\n","Epoch: 209, Train Acc: 1.0000\n","Epoch: 210, Train Acc: 1.0000\n","Epoch: 211, Train Acc: 1.0000\n","Epoch: 212, Train Acc: 1.0000\n","Epoch: 213, Train Acc: 1.0000\n","Epoch: 214, Train Acc: 1.0000\n","Epoch: 215, Train Acc: 1.0000\n","Epoch: 216, Train Acc: 1.0000\n","Epoch: 217, Train Acc: 1.0000\n","Epoch: 218, Train Acc: 1.0000\n","Epoch: 219, Train Acc: 1.0000\n","Epoch: 220, Train Acc: 1.0000\n","Epoch: 221, Train Acc: 1.0000\n","Epoch: 222, Train Acc: 1.0000\n","Epoch: 223, Train Acc: 1.0000\n","Epoch: 224, Train Acc: 1.0000\n","Epoch: 225, Train Acc: 1.0000\n","Epoch: 226, Train Acc: 1.0000\n","Epoch: 227, Train Acc: 1.0000\n","Epoch: 228, Train Acc: 1.0000\n","Epoch: 229, Train Acc: 1.0000\n","Epoch: 230, Train Acc: 0.9671\n","Epoch: 231, Train Acc: 0.9926\n","Epoch: 232, Train Acc: 0.9977\n","Epoch: 233, Train Acc: 0.9947\n","Epoch: 234, Train Acc: 0.9999\n","Epoch: 235, Train Acc: 0.9987\n","Epoch: 236, Train Acc: 0.9990\n","Epoch: 237, Train Acc: 0.9986\n","Epoch: 238, Train Acc: 1.0000\n","Epoch: 239, Train Acc: 0.9997\n","Epoch: 240, Train Acc: 0.9978\n","Epoch: 241, Train Acc: 0.9977\n","Epoch: 242, Train Acc: 0.9982\n","Epoch: 243, Train Acc: 0.9995\n","Epoch: 244, Train Acc: 0.9953\n","Epoch: 245, Train Acc: 0.9993\n","Epoch: 246, Train Acc: 0.9991\n","Epoch: 247, Train Acc: 1.0000\n","Epoch: 248, Train Acc: 1.0000\n","Epoch: 249, Train Acc: 1.0000\n","Epoch: 250, Train Acc: 1.0000\n","Epoch: 251, Train Acc: 1.0000\n","Epoch: 252, Train Acc: 1.0000\n","Epoch: 253, Train Acc: 1.0000\n","Epoch: 254, Train Acc: 1.0000\n","Epoch: 255, Train Acc: 1.0000\n","Epoch: 256, Train Acc: 1.0000\n","Epoch: 257, Train Acc: 1.0000\n","Epoch: 258, Train Acc: 1.0000\n","Epoch: 259, Train Acc: 1.0000\n","Epoch: 260, Train Acc: 1.0000\n","Epoch: 261, Train Acc: 1.0000\n","Epoch: 262, Train Acc: 1.0000\n","Epoch: 263, Train Acc: 1.0000\n","Epoch: 264, Train Acc: 1.0000\n","Epoch: 265, Train Acc: 1.0000\n","Epoch: 266, Train Acc: 1.0000\n","Epoch: 267, Train Acc: 1.0000\n","Epoch: 268, Train Acc: 1.0000\n","Epoch: 269, Train Acc: 1.0000\n","Epoch: 270, Train Acc: 1.0000\n","Epoch: 271, Train Acc: 1.0000\n","Epoch: 272, Train Acc: 1.0000\n","Epoch: 273, Train Acc: 1.0000\n","Epoch: 274, Train Acc: 1.0000\n","Epoch: 275, Train Acc: 1.0000\n","Epoch: 276, Train Acc: 1.0000\n","Epoch: 277, Train Acc: 1.0000\n","Epoch: 278, Train Acc: 1.0000\n","Epoch: 279, Train Acc: 1.0000\n","Epoch: 280, Train Acc: 1.0000\n","Epoch: 281, Train Acc: 1.0000\n","Epoch: 282, Train Acc: 1.0000\n","Epoch: 283, Train Acc: 1.0000\n","Epoch: 284, Train Acc: 1.0000\n","Epoch: 285, Train Acc: 1.0000\n","Epoch: 286, Train Acc: 1.0000\n","Epoch: 287, Train Acc: 1.0000\n","Epoch: 288, Train Acc: 1.0000\n","Epoch: 289, Train Acc: 1.0000\n","Epoch: 290, Train Acc: 1.0000\n","Epoch: 291, Train Acc: 1.0000\n","Epoch: 292, Train Acc: 1.0000\n","Epoch: 293, Train Acc: 1.0000\n","Epoch: 294, Train Acc: 1.0000\n","Epoch: 295, Train Acc: 1.0000\n","Epoch: 296, Train Acc: 1.0000\n","Epoch: 297, Train Acc: 1.0000\n","Epoch: 298, Train Acc: 1.0000\n","Epoch: 299, Train Acc: 1.0000\n","Epoch: 300, Train Acc: 1.0000\n","Epoch: 301, Train Acc: 1.0000\n","Epoch: 302, Train Acc: 1.0000\n","Epoch: 303, Train Acc: 1.0000\n","Epoch: 304, Train Acc: 0.8880\n","Epoch: 305, Train Acc: 0.9930\n","Epoch: 306, Train Acc: 0.9964\n","Epoch: 307, Train Acc: 0.9990\n","Epoch: 308, Train Acc: 0.9999\n","Epoch: 309, Train Acc: 0.9901\n","Epoch: 310, Train Acc: 0.9999\n","Epoch: 311, Train Acc: 1.0000\n","Epoch: 312, Train Acc: 0.9997\n","Epoch: 313, Train Acc: 0.9976\n","Epoch: 314, Train Acc: 0.9997\n","Epoch: 315, Train Acc: 0.9950\n","Epoch: 316, Train Acc: 0.9967\n","Epoch: 317, Train Acc: 0.9991\n","Epoch: 318, Train Acc: 0.9975\n","Epoch: 319, Train Acc: 0.9997\n","Epoch: 320, Train Acc: 0.9976\n","Epoch: 321, Train Acc: 0.9969\n","Epoch: 322, Train Acc: 0.9992\n","Epoch: 323, Train Acc: 0.9998\n","Epoch: 324, Train Acc: 0.9995\n","Epoch: 325, Train Acc: 0.9946\n","Epoch: 326, Train Acc: 0.9998\n","Epoch: 327, Train Acc: 1.0000\n","Epoch: 328, Train Acc: 1.0000\n","Epoch: 329, Train Acc: 1.0000\n","Epoch: 330, Train Acc: 1.0000\n","Epoch: 331, Train Acc: 1.0000\n","Epoch: 332, Train Acc: 1.0000\n","Epoch: 333, Train Acc: 1.0000\n","Epoch: 334, Train Acc: 1.0000\n","Epoch: 335, Train Acc: 1.0000\n","Epoch: 336, Train Acc: 1.0000\n","Epoch: 337, Train Acc: 1.0000\n","Epoch: 338, Train Acc: 1.0000\n","Epoch: 339, Train Acc: 1.0000\n","Epoch: 340, Train Acc: 1.0000\n","Epoch: 341, Train Acc: 1.0000\n","Epoch: 342, Train Acc: 1.0000\n","Epoch: 343, Train Acc: 1.0000\n","Epoch: 344, Train Acc: 1.0000\n","Epoch: 345, Train Acc: 1.0000\n","Epoch: 346, Train Acc: 1.0000\n","Epoch: 347, Train Acc: 1.0000\n","Epoch: 348, Train Acc: 1.0000\n","Epoch: 349, Train Acc: 1.0000\n","Epoch: 350, Train Acc: 1.0000\n","Epoch: 351, Train Acc: 1.0000\n","Epoch: 352, Train Acc: 1.0000\n","Epoch: 353, Train Acc: 1.0000\n","Epoch: 354, Train Acc: 1.0000\n","Epoch: 355, Train Acc: 1.0000\n","Epoch: 356, Train Acc: 1.0000\n","Epoch: 357, Train Acc: 1.0000\n","Epoch: 358, Train Acc: 1.0000\n","Epoch: 359, Train Acc: 1.0000\n","Epoch: 360, Train Acc: 1.0000\n","Epoch: 361, Train Acc: 1.0000\n","Epoch: 362, Train Acc: 1.0000\n","Epoch: 363, Train Acc: 1.0000\n","Epoch: 364, Train Acc: 1.0000\n","Epoch: 365, Train Acc: 1.0000\n","Epoch: 366, Train Acc: 1.0000\n","Epoch: 367, Train Acc: 1.0000\n","Epoch: 368, Train Acc: 1.0000\n","Epoch: 369, Train Acc: 1.0000\n","Epoch: 370, Train Acc: 1.0000\n","Epoch: 371, Train Acc: 0.9907\n","Epoch: 372, Train Acc: 0.9955\n","Epoch: 373, Train Acc: 0.9968\n","Epoch: 374, Train Acc: 0.9998\n","Epoch: 375, Train Acc: 0.9995\n","Epoch: 376, Train Acc: 0.9999\n","Epoch: 377, Train Acc: 1.0000\n","Epoch: 378, Train Acc: 1.0000\n","Epoch: 379, Train Acc: 1.0000\n","Epoch: 380, Train Acc: 1.0000\n","Epoch: 381, Train Acc: 1.0000\n","Epoch: 382, Train Acc: 1.0000\n","Epoch: 383, Train Acc: 1.0000\n","Epoch: 384, Train Acc: 1.0000\n","Epoch: 385, Train Acc: 1.0000\n","Epoch: 386, Train Acc: 1.0000\n","Epoch: 387, Train Acc: 1.0000\n","Epoch: 388, Train Acc: 1.0000\n","Epoch: 389, Train Acc: 1.0000\n","Epoch: 390, Train Acc: 1.0000\n","Epoch: 391, Train Acc: 0.9841\n","Epoch: 392, Train Acc: 0.9942\n","Epoch: 393, Train Acc: 0.9996\n","Epoch: 394, Train Acc: 0.9997\n","Epoch: 395, Train Acc: 0.9997\n","Epoch: 396, Train Acc: 1.0000\n","Epoch: 397, Train Acc: 1.0000\n","Epoch: 398, Train Acc: 1.0000\n","Epoch: 399, Train Acc: 1.0000\n","Epoch: 400, Train Acc: 1.0000\n","Epoch: 401, Train Acc: 1.0000\n","Epoch: 402, Train Acc: 1.0000\n","Epoch: 403, Train Acc: 1.0000\n","Epoch: 404, Train Acc: 1.0000\n","Epoch: 405, Train Acc: 1.0000\n","Epoch: 406, Train Acc: 1.0000\n","Epoch: 407, Train Acc: 1.0000\n","Epoch: 408, Train Acc: 1.0000\n","Epoch: 409, Train Acc: 1.0000\n","Epoch: 410, Train Acc: 1.0000\n","Epoch: 411, Train Acc: 1.0000\n","Epoch: 412, Train Acc: 1.0000\n","Epoch: 413, Train Acc: 1.0000\n","Epoch: 414, Train Acc: 1.0000\n","Epoch: 415, Train Acc: 1.0000\n","Epoch: 416, Train Acc: 1.0000\n","Epoch: 417, Train Acc: 1.0000\n","Epoch: 418, Train Acc: 1.0000\n","Epoch: 419, Train Acc: 1.0000\n","Epoch: 420, Train Acc: 1.0000\n","Epoch: 421, Train Acc: 1.0000\n","Epoch: 422, Train Acc: 1.0000\n","Epoch: 423, Train Acc: 1.0000\n","Epoch: 424, Train Acc: 1.0000\n","Epoch: 425, Train Acc: 1.0000\n","Epoch: 426, Train Acc: 1.0000\n","Epoch: 427, Train Acc: 1.0000\n","Epoch: 428, Train Acc: 1.0000\n","Epoch: 429, Train Acc: 1.0000\n","Epoch: 430, Train Acc: 1.0000\n","Epoch: 431, Train Acc: 1.0000\n","Epoch: 432, Train Acc: 1.0000\n","Epoch: 433, Train Acc: 1.0000\n","Epoch: 434, Train Acc: 1.0000\n","Epoch: 435, Train Acc: 1.0000\n","Epoch: 436, Train Acc: 1.0000\n","Epoch: 437, Train Acc: 1.0000\n","Epoch: 438, Train Acc: 1.0000\n","Epoch: 439, Train Acc: 1.0000\n","Epoch: 440, Train Acc: 0.9243\n","Epoch: 441, Train Acc: 0.9963\n","Epoch: 442, Train Acc: 0.9997\n","Epoch: 443, Train Acc: 0.9996\n","Epoch: 444, Train Acc: 0.9998\n","Epoch: 445, Train Acc: 1.0000\n","Epoch: 446, Train Acc: 0.9963\n","Epoch: 447, Train Acc: 0.9999\n","Epoch: 448, Train Acc: 1.0000\n","Epoch: 449, Train Acc: 1.0000\n","Epoch: 450, Train Acc: 1.0000\n","Epoch: 451, Train Acc: 1.0000\n","Epoch: 452, Train Acc: 1.0000\n","Epoch: 453, Train Acc: 1.0000\n","Epoch: 454, Train Acc: 1.0000\n","Epoch: 455, Train Acc: 1.0000\n","Epoch: 456, Train Acc: 1.0000\n","Epoch: 457, Train Acc: 1.0000\n","Epoch: 458, Train Acc: 1.0000\n","Epoch: 459, Train Acc: 1.0000\n","Epoch: 460, Train Acc: 0.9922\n","Epoch: 461, Train Acc: 0.9942\n","Epoch: 462, Train Acc: 0.9981\n","Epoch: 463, Train Acc: 0.9986\n","Epoch: 464, Train Acc: 0.9998\n","Epoch: 465, Train Acc: 0.9999\n","Epoch: 466, Train Acc: 1.0000\n","Epoch: 467, Train Acc: 1.0000\n","Epoch: 468, Train Acc: 1.0000\n","Epoch: 469, Train Acc: 1.0000\n","Epoch: 470, Train Acc: 1.0000\n","Epoch: 471, Train Acc: 1.0000\n","Epoch: 472, Train Acc: 1.0000\n","Epoch: 473, Train Acc: 0.9995\n","Epoch: 474, Train Acc: 0.9986\n","Epoch: 475, Train Acc: 0.9982\n","Epoch: 476, Train Acc: 0.9984\n","Epoch: 477, Train Acc: 0.9970\n","Epoch: 478, Train Acc: 0.9955\n","Epoch: 479, Train Acc: 0.9996\n","Epoch: 480, Train Acc: 0.9997\n","Epoch: 481, Train Acc: 0.9999\n","Epoch: 482, Train Acc: 0.9999\n","Epoch: 483, Train Acc: 1.0000\n","Epoch: 484, Train Acc: 1.0000\n","Epoch: 485, Train Acc: 1.0000\n","Epoch: 486, Train Acc: 1.0000\n","Epoch: 487, Train Acc: 1.0000\n","Epoch: 488, Train Acc: 1.0000\n","Epoch: 489, Train Acc: 1.0000\n","Epoch: 490, Train Acc: 1.0000\n","Epoch: 491, Train Acc: 1.0000\n","Epoch: 492, Train Acc: 0.9962\n","Epoch: 493, Train Acc: 0.9993\n","Epoch: 494, Train Acc: 0.9989\n","Epoch: 495, Train Acc: 0.9995\n","Epoch: 496, Train Acc: 1.0000\n","Epoch: 497, Train Acc: 1.0000\n","Epoch: 498, Train Acc: 1.0000\n","Epoch: 499, Train Acc: 1.0000\n","model saved as /content/gdrive/My Drive/Academia/OHSU/Proposal/resnet_trained_pytorch_model_fold_full_dataset.pt\n"],"name":"stdout"}]}]}